{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BSDSF22M031\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of customers dataset:\n",
      "   CustomerID  Age         City\n",
      "0           1   22     New York\n",
      "1           2   23  Los Angeles\n",
      "2           3   24      Chicago\n",
      "3           4   25      Houston\n",
      "4           5   26      Phoenix\n",
      "\n",
      "First few rows of sales dataset:\n",
      "   SaleID  CustomerID     Product  Amount\n",
      "0     101           1      Laptop     200\n",
      "1     102           2  Smartphone     500\n",
      "2     103           3      Tablet     800\n",
      "3     104           4  Headphones    1100\n",
      "4     105           5     Monitor    1400\n",
      "\n",
      "Shape of customers dataset: (100, 3)\n",
      "Shape of sales dataset: (400, 4)\n",
      "\n",
      "Missing values in customers dataset:\n",
      "CustomerID    0\n",
      "Age           0\n",
      "City          0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in sales dataset:\n",
      "SaleID        0\n",
      "CustomerID    0\n",
      "Product       0\n",
      "Amount        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\R c\\AppData\\Local\\Temp\\ipykernel_10772\\4052301783.py:24: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  customers_df.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\R c\\AppData\\Local\\Temp\\ipykernel_10772\\4052301783.py:25: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  sales_df.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Task 1: Load the datasets and perform initial inspection\n",
    "\n",
    "# Load datasets\n",
    "customers_df = pd.read_csv(\"customers.csv\")\n",
    "sales_df = pd.read_csv(\"sales.csv\")\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"First few rows of customers dataset:\")\n",
    "print(customers_df.head())\n",
    "print(\"\\nFirst few rows of sales dataset:\")\n",
    "print(sales_df.head())\n",
    "\n",
    "# Show total number of rows and columns\n",
    "print(\"\\nShape of customers dataset:\", customers_df.shape)\n",
    "print(\"Shape of sales dataset:\", sales_df.shape)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in customers dataset:\")\n",
    "print(customers_df.isnull().sum())\n",
    "print(\"\\nMissing values in sales dataset:\")\n",
    "print(sales_df.isnull().sum())\n",
    "\n",
    "# Handle missing values (if applicable)\n",
    "customers_df.fillna(method='ffill', inplace=True)\n",
    "sales_df.fillna(method='ffill', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Customers from New York (using dictionary): 20\n",
      "\n",
      "Customers from New York (using DataFrame): 20\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Convert customers data to a Python dictionary and filter customers by city\n",
    "\n",
    "# Convert to dictionary\n",
    "customers_dict = customers_df.to_dict('records')\n",
    "\n",
    "# Filter customers by city (e.g., 'New York') using dictionary\n",
    "filtered_customers_dict = [customer for customer in customers_dict if customer['City'] == 'New York']\n",
    "print(\"\\nCustomers from New York (using dictionary):\", len(filtered_customers_dict))\n",
    "\n",
    "# Filter customers by city using DataFrame\n",
    "filtered_customers_df = customers_df[customers_df['City'] == 'New York']\n",
    "print(\"\\nCustomers from New York (using DataFrame):\", len(filtered_customers_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate rows in customers dataset: 0\n",
      "Duplicate rows in sales dataset: 0\n",
      "\n",
      "Duplicates after cleaning (customers): 0\n",
      "Duplicates after cleaning (sales): 0\n"
     ]
    }
   ],
   "source": [
    "# Task 3: Identify and remove duplicate rows\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"\\nDuplicate rows in customers dataset:\", customers_df.duplicated().sum())\n",
    "print(\"Duplicate rows in sales dataset:\", sales_df.duplicated().sum())\n",
    "\n",
    "# Remove duplicates\n",
    "customers_df.drop_duplicates(inplace=True)\n",
    "sales_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Verify duplicates removal\n",
    "print(\"\\nDuplicates after cleaning (customers):\", customers_df.duplicated().sum())\n",
    "print(\"Duplicates after cleaning (sales):\", sales_df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total sales by product:\n",
      "      Product  DiscountedAmount\n",
      "0  Headphones           79200.0\n",
      "1      Laptop           14400.0\n",
      "2     Monitor          100800.0\n",
      "3  Smartphone           36000.0\n",
      "4      Tablet           57600.0\n"
     ]
    }
   ],
   "source": [
    "# Task 4: Add a column for discounted amount and group data by product\n",
    "\n",
    "# Add discounted column\n",
    "sales_df['DiscountedAmount'] = sales_df['Amount'] * 0.9\n",
    "\n",
    "# Group by product and calculate total sales\n",
    "product_sales = sales_df.groupby('Product')['DiscountedAmount'].sum().reset_index()\n",
    "print(\"\\nTotal sales by product:\")\n",
    "print(product_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "City distribution for customers aged 25-35:\n",
      "City\n",
      "Houston        11\n",
      "Phoenix         8\n",
      "New York        7\n",
      "Los Angeles     7\n",
      "Chicago         7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Task 5: Filter customers aged 25-35 and analyze city distribution\n",
    "\n",
    "# Filter customers\n",
    "filtered_age_customers = customers_df[(customers_df['Age'] >= 25) & (customers_df['Age'] <= 35)]\n",
    "\n",
    "# Analyze city distribution\n",
    "city_distribution = filtered_age_customers['City'].value_counts()\n",
    "print(\"\\nCity distribution for customers aged 25-35:\")\n",
    "print(city_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Quantity' column calculated and added to sales_df.\n",
      "\n",
      "Columns in merged dataset: Index(['SaleID', 'CustomerID', 'Product', 'Amount', 'DiscountedAmount',\n",
      "       'Quantity', 'Age', 'City'],\n",
      "      dtype='object')\n",
      "\n",
      "City with highest total sales:\n",
      "City      Phoenix\n",
      "Amount     112000\n",
      "Name: 4, dtype: object\n",
      "\n",
      "Product with most units sold:\n",
      "Product     Headphones\n",
      "Quantity            80\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Derive Quantity if not present\n",
    "if 'Quantity' not in sales_df.columns:\n",
    "    if 'Amount' in sales_df.columns and 'Price' in sales_df.columns:\n",
    "        # Calculate Quantity as Amount / Price\n",
    "        sales_df['Quantity'] = sales_df['Amount'] / sales_df['Price']\n",
    "        sales_df['Quantity'] = sales_df['Quantity'].fillna(0).astype(int)  # Handle NaNs and convert to integers\n",
    "    else:\n",
    "        # Default Quantity as 1 if no logic applies\n",
    "        sales_df['Quantity'] = 1\n",
    "    print(\"\\n'Quantity' column calculated and added to sales_df.\")\n",
    "\n",
    "# Merge datasets\n",
    "merged_df = pd.merge(sales_df, customers_df, on='CustomerID')\n",
    "\n",
    "# Verify merge columns\n",
    "print(\"\\nColumns in merged dataset:\", merged_df.columns)\n",
    "\n",
    "# Task 6 Analysis\n",
    "\n",
    "# City with highest total sales\n",
    "city_sales = merged_df.groupby('City')['Amount'].sum().reset_index()\n",
    "highest_sales_city = city_sales.loc[city_sales['Amount'].idxmax()]\n",
    "print(\"\\nCity with highest total sales:\")\n",
    "print(highest_sales_city)\n",
    "\n",
    "# Product with most units sold\n",
    "product_units = merged_df.groupby('Product')['Quantity'].sum().reset_index()\n",
    "most_units_product = product_units.loc[product_units['Quantity'].idxmax()]\n",
    "print(\"\\nProduct with most units sold:\")\n",
    "print(most_units_product)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique cities: ['New York' 'Los Angeles' 'Chicago' 'Houston' 'Phoenix']\n",
      "Unique products: ['Laptop' 'Smartphone' 'Tablet' 'Headphones' 'Monitor']\n",
      "\n",
      "Mean of Amount column: 800.0\n",
      "Median of Amount column: 800.0\n",
      "\n",
      "Analysis complete. Cleaned and merged data saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "# Task 7: Explore merged dataset for insights\n",
    "\n",
    "# Unique values in City and Product columns\n",
    "unique_cities = merged_df['City'].unique()\n",
    "unique_products = merged_df['Product'].unique()\n",
    "print(\"\\nUnique cities:\", unique_cities)\n",
    "print(\"Unique products:\", unique_products)\n",
    "\n",
    "# Mean and median of Amount column\n",
    "mean_amount = merged_df['Amount'].mean()\n",
    "median_amount = merged_df['Amount'].median()\n",
    "print(\"\\nMean of Amount column:\", mean_amount)\n",
    "print(\"Median of Amount column:\", median_amount)\n",
    "\n",
    "# Save cleaned data to new files\n",
    "filtered_age_customers.to_csv(\"filtered_customers.csv\", index=False)\n",
    "merged_df.to_csv(\"merged_data.csv\", index=False)\n",
    "\n",
    "print(\"\\nAnalysis complete. Cleaned and merged data saved to CSV files.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
